import json
import httpx
from bson import ObjectId
from .config import settings
from .repositories import get_all_roles
from .translations import translate_list, TRANSLATION_MAP
import re

def clean_for_json(obj):
    """×”××¨×ª ××•×‘×™×™×§×˜×™× ×œ× ×ª×•×××™ JSON (×›×’×•×Ÿ ObjectId) ×œ××—×¨×•×–×•×ª."""
    if isinstance(obj, dict):
        return {k: clean_for_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [clean_for_json(i) for i in obj]
    elif isinstance(obj, ObjectId):
        return str(obj)
    else:
        return obj

async def extract_traits_from_text(text: str, gender: str = "×–×›×¨") -> list[str]:
    """
    ×©×•×œ×— ×˜×§×¡×˜ ×—×•×¤×©×™ ×œÖ¾LLM ×›×“×™ ×œ×—×œ×¥ ×ª×›×•× ×•×ª ××•×¤×™ ×›×œ×œ×™×•×ª ×‘×¢×‘×¨×™×ª,
    ×•××—×–×™×¨ ×¨×©×™××” ×©×œ ××¤×ª×—×•×ª ××ª×•×š TRANSLATION_MAP (normalized keys).
    """
    prompt = (
        f"×”×˜×§×¡×˜ ×”×‘× ×”×•× ×ª×™××•×¨ ×—×•×¤×©×™ ×©×œ ××•×¢××“ ×œ×©×™×¨×•×ª ×‘×™×˜×—×•× ×™:\n"
        f"××™×Ÿ: {gender}\n"
        f'"{text}"\n\n'
        "× ×ª×— ××ª ×ª×›×•× ×•×ª ×”××•×¤×™ ××ª×•×š ×”×˜×§×¡×˜ ×‘×œ×‘×“.\n"
        "×”××˜×¨×” ×”×™× ×œ×”×¡×‘×™×¨ ××™×œ×• ×ª×›×•× ×•×ª ×™×© ×œ××•×¢××“ ×‘×©×¤×” × ×’×™×©×” ×•×‘×¨×•×¨×” â€“ ×œ××©×œ: ×—×‘×¨×•×ª×™, ××—×¨××™, ×™×•×–×.\n"
        "××œ ×ª×—×–×•×¨ ×¢×œ ××©×¤×˜×™× ××”×˜×§×¡×˜ ×”××§×•×¨×™.\n"
        "×¢× ×” ×‘×¢×‘×¨×™×ª ×‘×œ×‘×“.\n"
        "×”×—×–×¨ ××ª ×”×ª×›×•× ×•×ª ×‘×œ×‘×“, ××•×¤×¨×“×•×ª ×‘×¤×¡×™×§×™×, ×‘×œ×™ ×ª×•×¡×¤×•×ª ××• ×¤×ª×™×—×™×.\n"
        "×©×™× ×œ×‘: ×× ×”××™×Ÿ ×”×•× × ×§×‘×”, ×”×—×–×¨ ×ª×©×•×‘×” ×‘×œ×©×•×Ÿ × ×§×‘×” ×‘×œ×‘×“."
    )

    payload = {
        "model": "meta-llama/llama-3-70b-instruct",
        "messages": [
            {"role": "system", "content": "××ª×” ×¢×•×–×¨ ×‘×¡×™×•×•×’ ×ª×›×•× ×•×ª ××™×©×™×•×ª ×œ×¦×”×´×œ."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.3,
        "max_tokens": 300
    }

    headers = {
        "Authorization": f"Bearer {settings.openrouter_api_key}",
        "HTTP-Referer": "https://github.com/YuvalBZ/fastapi_project",
        "X-Title": "Trait Extractor",
        "Content-Type": "application/json",
    }

    try:
        async with httpx.AsyncClient() as client:
            res = await client.post(
                "https://openrouter.ai/api/v1/chat/completions",
                json=payload,
                headers=headers
            )
        res.raise_for_status()
        content = res.json().get("choices", [{}])[0].get("message", {}).get("content", "").strip()
        if not content:
            raise ValueError("×ª×©×•×‘×ª ×”Ö¾API ×¨×™×§×”.")

        # ×¤×™×¦×•×œ ×œ×ª×›×•× ×•×ª
        raw_traits = re.split(r",| ×•|\n|\.|\s-\s", content)
        traits = [t.strip() for t in raw_traits if t.strip() and len(t.strip()) > 1]

        # × ×™×¡×™×•×Ÿ ×œ××¤×•×ª ×›×œ ×ª×›×•× ×” ×œ××¤×ª×— ×‘××¤×”
        normalized_keys = []
        for trait in traits:
            match_found = False
            for key, val in TRANSLATION_MAP.items():
                if isinstance(val, dict) and trait in val.values():
                    normalized_keys.append(key)
                    match_found = True
                    break
                elif isinstance(val, str) and trait == val:
                    normalized_keys.append(key)
                    match_found = True
                    break
            if not match_found:
                print(f"âš ï¸ ×ª×›×•× ×” ×œ× ××–×•×”×”: {trait}")
                normalized_keys.append(trait)  # ×× ××™×Ÿ ×”×ª×××” â€“ ×©×•××¨ ××ª ×”×˜×§×¡×˜ ×”××§×•×¨×™

        return normalized_keys

    except Exception as e:
        print(f"âŒ Trait extraction failed: {e}")
        raise


async def ai_recommend(profile: dict, roles: list[dict] = None, db=None) -> list[dict]:
    """××—×–×™×¨ 3 ×ª×¤×§×™×“×™× ××ª××™××™× ×‘×¤×•×¨××˜: [{score, role: {name, description, requirements...}}]"""
    roles = await get_all_roles()

    system_msg = (
    "××ª×” ××•××—×” ×‘×”×ª×××ª ×¤×¨×•×¤×™×œ×™× ××™×©×™×™× ×œ×ª×¤×§×™×“×™× ×¦×‘××™×™× ×‘×¦×”\"×œ.\n"
    "×›×œ ×ª×¤×§×™×“ ××›×™×œ ××ª ×©×“×” 'type' ×©××ª××¨ ××ª ×”×¡×•×’ ×”×›×œ×œ×™ ×©×œ×•: ×œ×•×—××”, ××•×“×™×¢×™×Ÿ, ×˜×›× ×•×œ×•×’×™, ×ª×•××š ×œ×—×™××”, ×”×“×¨×›×”, ×•×›×•'.\n\n"
    "×”×¤×¨×•×¤×™×œ ×›×•×œ×œ ××ª: ×©×, ×’×™×œ, ××™×Ÿ, ×¨××ª ×›×•×©×¨ ×’×•×¤× ×™ (1â€“5), ×›×™×©×•×¨×™× ×˜×›× ×™×™×, ×ª×›×•× ×•×ª ××•×¤×™, ×©×¤×•×ª, ×•×ª×™××•×¨ ×—×•×¤×©×™.\n"
    "×©×™× ×œ×‘:\n"
    "- ×¡×§×œ×ª ×”×›×•×©×¨ ×”×’×•×¤× ×™ ×”×™× ×‘×™×Ÿ 1 (×›×•×©×¨ × ××•×š ×××•×“) ×œÖ¾5 (×›×•×©×¨ ×’×‘×•×” ×××•×“).\n"
    "- ××œ ×ª××œ×™×¥ ×¢×œ ×ª×¤×§×™×“×™× ×¢× ×“×¨×™×©×•×ª ×›×•×©×¨ ×’×‘×•×”×•×ª ×× ×”×›×•×©×¨ ×”×•× 1â€“2.\n"
    "- ×× ×”×›×•×©×¨ ×”×’×•×¤× ×™ ×”×•× 4 ××• 5, ×•×”×ª×›×•× ×•×ª ×›×•×œ×œ×•×ª ×”×§×¨×‘×”, ×¢×‘×•×“×ª ×¦×•×•×ª ××• ×¡×¤×•×¨×˜×™×‘×™×•×ª â€“ ×—×•×‘×” ×œ×”××œ×™×¥ ×¢×œ ×ª×¤×§×™×“ ××—×“ ×œ×¤×—×•×ª ××¡×•×’ ×§×¨×‘×™, ××œ ×ª××œ×™×¥ ×¢×œ ×ª×¤×§×™×“ ×¢× ×¤×¨×•×¤×™×œ ×¨×¤×•××™ × ××•×š ×-82. (type='×œ×•×—××”').\n"
    "- ×× ×©×¤×•×ª ×›××• ×¢×¨×‘×™×ª ××• ×¤×¨×¡×™×ª ××•×¤×™×¢×•×ª ×‘×¤×¨×•×¤×™×œ â€“ ×—×•×‘×” ×œ×”××œ×™×¥ ×¢×œ ×œ×¤×—×•×ª ×ª×¤×§×™×“ ××—×“ ××¡×•×’ ××•×“×™×¢×™×Ÿ (type='××•×“×™×¢×™×Ÿ').\n\n"
    "- ×× ××“×•×‘×¨ ×‘× ×§×‘×” ×ª×¦×™×¢ ×œ×” ×ª×¤×§×™×“ (type='×× ×•×©×™') ×›××• ××©×§×™×ª.\n\n"
    "×©×§×œ ××ª ×”×”×ª×××” ×œ×¤×™:\n"
    "- 30% ×ª×›×•× ×•×ª ××•×¤×™ (traits)\n"
    "- 30% ×›×™×©×•×¨×™× ×˜×›× ×™×™× (tech)\n"
    "- 25% ×›×•×©×¨ ×’×•×¤× ×™\n"
    "- 15% ×©×¤×•×ª\n\n"
    "×”×—×–×¨ JSON ×‘×œ×‘×“. ××‘× ×” ×›×œ ×”××œ×¦×”:\n"
    "- role_id (××–×”×” ×”×ª×¤×§×™×“ ×××¡×“ ×”× ×ª×•× ×™×)\n"
    "- score (×¦×™×•×Ÿ ×”×ª×××” ×-0 ×¢×“ 100)\n"
    "- ×¢×œ×™×š ×œ×”×—×–×™×¨ ××š ×•×¨×§ ××–×”×™ ×ª×¤×§×™×“×™× ×ª×§×¤×™× ×××¡×“ ×”× ×ª×•× ×™×"
    "×”×—×–×¨ ×‘×“×™×•×§ 3 ×”××œ×¦×•×ª. ××™×Ÿ ×œ×¢×˜×•×£ ××ª ×”×ª×©×•×‘×” ×‘××•×‘×™×™×§×˜ × ×•×¡×£. ×× ××“×•×‘×¨ ×‘× ×§×‘×”, ×›×ª×•×‘ ×‘×œ×©×•×Ÿ × ×§×‘×” ×›×•×œ×œ ×ª×›×•× ×•×ª ×‘×œ×©×•×Ÿ × ×§×‘×”."
)
    
    system_msg += (
    "\n\n ×”× ×—×™×•×ª ×—×©×•×‘×•×ª ×××•×“:\n"
    "- ××œ ×ª×•×¡×™×£ ×”×¡×‘×¨×™× ××• ×˜×§×¡×˜ ×—×•×¤×©×™.\n"
    "- ××œ ×ª×¦×¨×£ ×›×•×ª×¨×•×ª, ×¡×™×‘×•×ª, ××• ×˜×§×¡×˜×™× × ×•×¡×¤×™× â€“ ×”×—×–×¨ JSON ×ª×§× ×™ ×‘×œ×‘×“!\n"
    "- ××œ ×ª×›×ª×•×‘ 'role:' ××• 'Reason:'.\n"
    "- ×”×—×–×¨ ××š ×•×¨×§ ××¢×¨×š JSON ×‘×¤×•×¨××˜: [{\"role_id\": \"...\", \"score\": 95}, ...]\n"
)

    payload = {
    "model": "meta-llama/llama-3-70b-instruct",
    "messages": [
        {
            "role": "system",
            "content": system_msg
        },
        {
            "role": "user",
            "content": json.dumps({
                "profile": clean_for_json(profile),
                "roles": clean_for_json(roles)
            }, ensure_ascii=False)
        }
    ],
    "temperature": 0.0,
    "max_tokens": 800
}

    headers = {
        "Authorization": f"Bearer {settings.openrouter_api_key}",
        "HTTP-Referer": "https://github.com/YuvalBZ/fastapi_project",
        "X-Title": "Role Matcher",
        "Content-Type": "application/json",
    }

    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            res = await client.post(
                "https://openrouter.ai/api/v1/chat/completions",  
                json=payload,
                headers=headers
            )

        res.raise_for_status()
        print(f"ğŸ“¬ Raw API response: {res.text}")

        content = res.json().get("choices", [{}])[0].get("message", {}).get("content", "").strip()

        if not content:
            raise ValueError("×œ× ×”×ª×§×‘×œ×• ×ª×•×¦××•×ª ××”-API, ×”×ª×©×•×‘×” ×¨×™×§×”.")

        try:
            parsed = json.loads(content)
        except json.JSONDecodeError:
            # × ×¡×” ×œ×—×œ×¥ JSON ××ª×•×š ×”×˜×§×¡×˜
            match = re.search(r"(\[\s*{.*?}\s*\])", content, re.DOTALL)
            if match:
                parsed = json.loads(match.group(1))
            else:
                raise ValueError("âš ï¸ ×œ× ×”×¦×œ×—×ª×™ ×œ×—×œ×¥ JSON ×ª×§× ×™ ××”×ª×©×•×‘×” ×©×œ ×”××•×“×œ.")

        if not isinstance(parsed, list) or not all("role_id" in r and "score" in r for r in parsed):
            raise ValueError("ğŸ“­ ×¤×•×¨××˜ ×œ× ×¦×¤×•×™ ×‘×ª×©×•×‘×ª ×”Ö¾API")

        enriched = []
        for r in parsed:
            role_doc = await db.roles.find_one({"_id": ObjectId(r["role_id"])})
            if role_doc:
                enriched.append({
                    "score": r["score"],
                    "role": clean_for_json(role_doc)
                })

        return enriched

    except httpx.HTTPStatusError as e:
        print(f"âŒ HTTP error from API: {e.response.status_code} - {e.response.text}")
        raise
    except json.JSONDecodeError as e:
        print(f"âŒ ×©×’×™××” ×‘×¤×¢× ×•×— JSON: {e}")
        raise
    except Exception as e:
        print(f"âŒ ×§×¨×ª×” ×©×’×™××” ×œ× ×¦×¤×•×™×”: {e}")
        raise

async def generate_profile_summary(profile: dict) -> str:
    traits = profile.get("personality_traits", [])
    fitness = profile.get("physical_fitness", None)
    languages = profile.get("languages", [])
    tech = profile.get("technical_skills", [])
    gender = profile.get("gender", "×–×›×¨")

    is_female = gender == "× ×§×‘×”"
    pronoun = "××ª" if is_female else "××ª×”"
    suffix = "×ª" if is_female else ""

    lines = []

    # ×¤×ª×™×— ×¢× ×ª×›×•× ×•×ª
    if traits:
        translated_traits = translate_list(traits[:5], gender="female" if is_female else "male")

        if len(translated_traits) == 1:
            traits_str = translated_traits[0]
        elif len(translated_traits) > 1:
            traits_str = ", ".join(translated_traits[:-1]) + " ×•" + translated_traits[-1]
        else:
            traits_str = ""

        if traits_str:
            lines.append(
                f"×•×•××•! ×ª×•×“×” ×¢×œ ×”×©×™×ª×•×£. × ×©××¢ ×©{pronoun} {traits_str}. "
                f"×ª×›×•× ×•×ª ××œ×• ×¢×©×•×™×•×ª ×œ×”×ª××™× ×œ×ª×¤×§×™×“×™× ××¡×•×™××™× ×‘×¦×”\"×œ."
            )
        else:
            lines.append("×•×•××•! ×ª×•×“×” ×¢×œ ×”×©×™×ª×•×£. × ×ª×—×™×œ ×œ×‘×—×•×Ÿ ××ª ×”×”×ª×××” ×©×œ×š ×œ×ª×¤×§×™×“×™× ×©×•× ×™× ×‘×¦×”\"×œ.")

    # ×›×•×©×¨ ×’×•×¤× ×™
    if fitness is not None:
        if fitness <= 2:
            lines.append(
                f"×”×›×•×©×¨ ×”×’×•×¤× ×™ ×©×œ×š × ××•×š ×™×—×¡×™×ª (×¨××” {fitness} ××ª×•×š 5), ×•×œ×›×Ÿ ×”××œ×¦× ×• ×¢×œ ×ª×¤×§×™×“×™× ×©××™× × ×“×•×¨×©×™× ××××¥ ×¤×™×–×™."
            )
        elif fitness >= 4:
            lines.append(
                "×¨××ª ×”×›×•×©×¨ ×”×’×•×¤× ×™ ×©×œ×š ×’×‘×•×”×”, ×•×œ×›×Ÿ ×¤×ª×—× ×• ×’× ××¤×©×¨×•×ª ×œ×ª×¤×§×™×“×™× ×¢× ×“×¨×™×©×” ×¤×™×–×™×ª."
            )

    # ×©×¤×•×ª
    relevant_langs = [lang for lang in languages if lang in ["×¢×¨×‘×™×ª", "×¤×¨×¡×™×ª", "×¨×•×¡×™×ª"]]
    if relevant_langs:
        langs_str = ", ".join(relevant_langs)
        lines.append(f"×©×¤×•×ª ×©×¦×•×™× ×• ×›××• {langs_str} ×¢×©×•×™×•×ª ×œ×”×ª××™× ×‘××™×•×—×“ ×œ×ª×¤×§×™×“×™× ××•×“×™×¢×™× ×™×™×.")

    # ×›×™×©×•×¨×™× ×˜×›× ×™×™×
    relevant_tech = [t for t in tech if any(x in t.lower() for x in ["×ª×›× ×•×ª", "×¡×™×™×‘×¨", "×˜×›× ×•×œ×•×’", "×¨×•×‘×•×˜"])]
    if relevant_tech:
        tech_str = ", ".join(relevant_tech)
        lines.append(
            f"×”××¢×¨×›×ª ×–×™×”×ª×” ×›×™×©×•×¨×™× ×˜×›× ×•×œ×•×’×™×™× ×›××• {tech_str}, ×•×œ×›×Ÿ ×©×§×œ× ×• ×ª×¤×§×™×“×™× ×‘×ª×—×•××™× ×˜×›× ×•×œ×•×’×™×™× ×•×”×“×¨×›×ª×™×™×."
        )

    if not lines:
        return "× ×•×ª×—×ª ×”×”×ª×××” ×œ×¤×™ ×”×ª×›×•× ×•×ª ×©××™×œ××ª ×‘×˜×•×¤×¡ ×•×”×¤×¨×˜×™× ×”××™×©×™×™× ×©×¡×™×¤×§×ª."

    return "\n\n".join(lines)
